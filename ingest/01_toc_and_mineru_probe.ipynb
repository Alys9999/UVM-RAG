{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f2adc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded.\n",
      "PDF_PATH: c:\\Users\\41v1r\\NEU\\NLP\\UVM-RAG\\data\\UVM_Class_Reference_Manual_1.2.pdf\n",
      "MINERU_OUT_DIR: c:\\Users\\41v1r\\NEU\\NLP\\UVM-RAG\\work\\mineru_out\n",
      "OUT_JSONL_PATH: c:\\Users\\41v1r\\NEU\\NLP\\UVM-RAG\\work\\json_out\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: configuration, imports, basic helpers\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import re\n",
    "import subprocess\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "ROOT = Path.cwd().parent\n",
    "\n",
    "# === Configure your paths here ===\n",
    "PDF_PATH = ROOT / \"data/UVM_Class_Reference_Manual_1.2.pdf\"\n",
    "MINERU_OUT_DIR = ROOT/ \"work/mineru_out/\"\n",
    "OUT_JSONL_PATH = ROOT / \"work/json_out\"\n",
    "STD_TAG = \"UVM-1.2\"  # you can change to exact standard name if you like\n",
    "\n",
    "# Regex for numeric heading inside TOC titles (e.g., \"5.3.11.2 do_unpack\")\n",
    "HDR_NUM_ID = re.compile(r\"^\\s*((?:\\d+)(?:\\.\\d+)*)\\s+(.*)$\")\n",
    "\n",
    "# Regex for numeric heading inside body text (e.g., \"5.3.11.2 do_unpack\")\n",
    "NUM_HEAD_RE = re.compile(r\"^\\s*(\\d+(?:\\.\\d+)*)(?:\\s+(.*))?$\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TocNode:\n",
    "    level: int          # 1 = chapter, 2 = section, etc.\n",
    "    id: Optional[str]   # \"5.3.11.2\" or None if not numeric\n",
    "    title: str          # pure text title, no numeric prefix\n",
    "    start: int          # 1-based start page\n",
    "    end: int            # 1-based end page (inclusive)\n",
    "\n",
    "\n",
    "def _normalize_text(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "print(\"Config loaded.\")\n",
    "print(\"PDF_PATH:\", PDF_PATH)\n",
    "print(\"MINERU_OUT_DIR:\", MINERU_OUT_DIR)\n",
    "print(\"OUT_JSONL_PATH:\", OUT_JSONL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e66af62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[toc] intervals built: 169 entries\n",
      "[toc] example entry: TocNode(level=1, id=None, title='UVM Class 1.2 Reference', start=1, end=3)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: TOC handling (numeric + text) and immediate run\n",
    "\n",
    "def build_toc_intervals(pdf_path: Path) -> List[TocNode]:\n",
    "    \"\"\"\n",
    "    Read PDF outline, accept both numeric and non-numeric titles, and build\n",
    "    page intervals [start, end] for each TOC node.\n",
    "\n",
    "    - If a title starts with a numeric id, e.g. \"5.3.11.2 do_unpack\",\n",
    "      we store id=\"5.3.11.2\" and title=\"do_unpack\".\n",
    "    - If there is no numeric prefix, id=None and title is the full text.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path.as_posix())\n",
    "    raw = doc.get_toc(simple=True)  # [[level, title, page], ...]\n",
    "    tmp: List[Dict[str, Any]] = []\n",
    "\n",
    "    for lvl, title, page in raw:\n",
    "        title = str(title).strip()\n",
    "        m = HDR_NUM_ID.match(title)\n",
    "        if m:\n",
    "            numeric_id = m.group(1)        # e.g. \"5.3.11.2\"\n",
    "            pure_title = m.group(2).strip()\n",
    "        else:\n",
    "            numeric_id = None\n",
    "            pure_title = title\n",
    "        tmp.append(\n",
    "            {\n",
    "                \"level\": int(lvl),\n",
    "                \"id\": numeric_id,\n",
    "                \"title\": pure_title,\n",
    "                \"page\": int(page),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Build [start, end] intervals using a stack\n",
    "    stack: List[Dict[str, Any]] = []\n",
    "    intervals: List[TocNode] = []\n",
    "\n",
    "    for e in tmp:\n",
    "        while stack and stack[-1][\"level\"] >= e[\"level\"]:\n",
    "            done = stack.pop()\n",
    "            end_page = e[\"page\"] - 1\n",
    "            intervals.append(\n",
    "                TocNode(\n",
    "                    level=done[\"level\"],\n",
    "                    id=done[\"id\"],\n",
    "                    title=done[\"title\"],\n",
    "                    start=done[\"page\"],\n",
    "                    end=end_page,\n",
    "                )\n",
    "            )\n",
    "        e[\"start\"] = e[\"page\"]\n",
    "        stack.append(e)\n",
    "\n",
    "    last_page = doc.page_count\n",
    "    while stack:\n",
    "        done = stack.pop()\n",
    "        intervals.append(\n",
    "            TocNode(\n",
    "                level=done[\"level\"],\n",
    "                id=done[\"id\"],\n",
    "                title=done[\"title\"],\n",
    "                start=done[\"page\"],\n",
    "                end=last_page,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Sort by (start asc, level desc) so deepest nodes come first per page\n",
    "    intervals.sort(key=lambda x: (x.start, -x.level))\n",
    "    print(f\"[toc] intervals built: {len(intervals)} entries\")\n",
    "    return intervals\n",
    "\n",
    "\n",
    "def section_fields_for_page(page: int, intervals: List[TocNode]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Pick the deepest TOC node covering `page` and derive base section fields.\n",
    "\n",
    "    - Always provide section_title from TOC.\n",
    "    - If TOC has a numeric id, derive chapter/section/subsection from it.\n",
    "    - header_path is the numeric id split on dots, when available.\n",
    "    \"\"\"\n",
    "    candidates = [n for n in intervals if n.start <= page <= n.end]\n",
    "    if not candidates:\n",
    "        return {}\n",
    "    candidates.sort(key=lambda n: n.level, reverse=True)\n",
    "    chosen = candidates[0]\n",
    "\n",
    "    meta: Dict[str, Any] = {\n",
    "        \"section_title\": chosen.title,\n",
    "    }\n",
    "\n",
    "    if chosen.id:\n",
    "        parts = chosen.id.split(\".\")\n",
    "        meta[\"header_path\"] = parts\n",
    "        if len(parts) >= 1:\n",
    "            meta[\"chapter\"] = parts[0]\n",
    "        if len(parts) >= 2:\n",
    "            meta[\"section\"] = \".\".join(parts[:2])\n",
    "        if len(parts) >= 3:\n",
    "            meta[\"subsection\"] = \".\".join(parts[:3])\n",
    "\n",
    "    return meta\n",
    "\n",
    "\n",
    "# === Run TOC extraction immediately ===\n",
    "toc_intervals = build_toc_intervals(PDF_PATH)\n",
    "if not toc_intervals:\n",
    "    print(\"[toc] WARNING: no TOC entries found; section fields may be empty.\")\n",
    "else:\n",
    "    print(\"[toc] example entry:\", toc_intervals[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e24d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: MinerU runner and immediate run\n",
    "\n",
    "def run_mineru(pdf_path: Path, out_dir: Path, rebuild: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Run MinerU CLI on the given PDF, unless outputs already exist and rebuild is False.\n",
    "\n",
    "    - If out_dir already contains any file, we assume MinerU has been run and\n",
    "      skip unless rebuild=True.\n",
    "    - This function does not require GPU; MinerU can run on CPU.\n",
    "    \"\"\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if not rebuild:\n",
    "        existing = list(out_dir.rglob(\"*\"))\n",
    "        if any(p.is_file() for p in existing):\n",
    "            print(f\"[mineru] outputs detected in {out_dir}; skipping because rebuild=False.\")\n",
    "            return\n",
    "\n",
    "    cmd = [\"mineru\", \"-p\", pdf_path.as_posix(), \"-o\", out_dir.as_posix()]\n",
    "    print(f\"[mineru] running: {' '.join(cmd)}\")\n",
    "    subprocess.run(cmd, check=True)\n",
    "    print(\"[mineru] done.\")\n",
    "\n",
    "\n",
    "# === Run MinerU once ===\n",
    "# Set rebuild=True only if you want to force re-running MinerU.\n",
    "run_mineru(PDF_PATH, MINERU_OUT_DIR, rebuild=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51c386c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mineru] using content list: UVM_Class_Reference_Manual_1.2\\auto\\UVM_Class_Reference_Manual_1.2_content_list.json\n",
      "[mineru] loaded 8167 text/title blocks with page_idx\n",
      "Example block: ('Universal Verification Methodology (UVM) 1.2 Class Reference', 1)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: load MinerU blocks with page numbers\n",
    "\n",
    "def load_mineru_blocks_with_pages(out_dir: Path) -> List[Tuple[str, int]]:\n",
    "    \"\"\"\n",
    "    Load MinerU's structured output (content_list.json) and return\n",
    "    a list of (text, page_no) pairs, where page_no is 1-based.\n",
    "\n",
    "    - We search recursively for *content_list.json under out_dir.\n",
    "    - We only keep blocks where type is \"text\" or \"title\".\n",
    "    - page_idx from MinerU is 0-based; we convert to 1-based page numbers.\n",
    "    \"\"\"\n",
    "    candidates = list(out_dir.rglob(\"*content_list.json\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No content_list.json found under {out_dir}. \"\n",
    "            \"Please check MinerU output structure.\"\n",
    "        )\n",
    "\n",
    "    cl_path = candidates[0]\n",
    "    print(f\"[mineru] using content list: {cl_path.relative_to(out_dir)}\")\n",
    "\n",
    "    raw = json.loads(cl_path.read_text(encoding=\"utf-8\", errors=\"ignore\"))\n",
    "    blocks_with_pages: List[Tuple[str, int]] = []\n",
    "\n",
    "    for item in raw:\n",
    "        if not isinstance(item, dict):\n",
    "            continue\n",
    "        ttype = item.get(\"type\")\n",
    "        if ttype not in (\"text\", \"title\"):\n",
    "            continue\n",
    "\n",
    "        text = item.get(\"text\") or \"\"\n",
    "        text = _normalize_text(str(text))\n",
    "        if not text or len(text) < 20:\n",
    "            continue\n",
    "\n",
    "        page_idx = item.get(\"page_idx\")\n",
    "        if page_idx is None:\n",
    "            continue\n",
    "        page_no = int(page_idx) + 1  # convert 0-based to 1-based\n",
    "        blocks_with_pages.append((text, page_no))\n",
    "\n",
    "    print(f\"[mineru] loaded {len(blocks_with_pages)} text/title blocks with page_idx\")\n",
    "    if not blocks_with_pages:\n",
    "        raise RuntimeError(\n",
    "            f\"content_list.json at {cl_path} contained no usable text/title blocks.\"\n",
    "        )\n",
    "\n",
    "    return blocks_with_pages\n",
    "\n",
    "\n",
    "# === Load MinerU blocks now ===\n",
    "blocks_with_pages = load_mineru_blocks_with_pages(MINERU_OUT_DIR)\n",
    "print(\"Example block:\", blocks_with_pages[0] if blocks_with_pages else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63401ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[emit] wrote 8167 records to c:\\Users\\41v1r\\NEU\\NLP\\UVM-RAG\\work\\json_out (2361.8 KB)\n",
      "Done. JSONL ready at: c:\\Users\\41v1r\\NEU\\NLP\\UVM-RAG\\work\\json_out\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: numeric heading extraction + JSONL writing\n",
    "\n",
    "def extract_numeric_heading(block: str) -> Tuple[Optional[str], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Try to parse a leading numeric section id from the block's first line.\n",
    "\n",
    "    Returns (sec_id, sec_title), e.g., (\"5.3.11.2\", \"do_unpack\").\n",
    "    If not found, returns (None, None).\n",
    "    \"\"\"\n",
    "    first_line = block.splitlines()[0].strip()\n",
    "    m = NUM_HEAD_RE.match(first_line)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    sec_id = m.group(1)\n",
    "    title = m.group(2) or \"\"\n",
    "    return sec_id, title.strip()\n",
    "\n",
    "\n",
    "def write_jsonl(\n",
    "    out_path: Path,\n",
    "    pdf_name: str,\n",
    "    std: str,\n",
    "    blocks_with_pages: List[Tuple[str, int]],\n",
    "    toc_intervals: List[TocNode],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Emit a JSONL file where each line represents one text block with:\n",
    "\n",
    "    - type=\"text\"\n",
    "    - page_from, page_to\n",
    "    - std (e.g. \"UVM-1.2\")\n",
    "    - uri=\"/pdf/<pdf_name>.pdf\"\n",
    "    - anchor=\"#page=<page_from>\"\n",
    "    - section metadata:\n",
    "        * section_title (from TOC, overridden by numeric heading if present)\n",
    "        * chapter / section / subsection / header_path (from TOC or block)\n",
    "    - content\n",
    "    \"\"\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    total = 0\n",
    "\n",
    "    with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for text, page in blocks_with_pages:\n",
    "            # base metadata from TOC (text title and possible numeric id)\n",
    "            meta = section_fields_for_page(page, toc_intervals)\n",
    "\n",
    "            # refine with numeric heading from the block itself\n",
    "            sec_id, sec_title = extract_numeric_heading(text)\n",
    "            if sec_id:\n",
    "                parts = sec_id.split(\".\")\n",
    "                meta[\"header_path\"] = parts\n",
    "                if len(parts) >= 1:\n",
    "                    meta[\"chapter\"] = parts[0]\n",
    "                if len(parts) >= 2:\n",
    "                    meta[\"section\"] = \".\".join(parts[:2])\n",
    "                if len(parts) >= 3:\n",
    "                    meta[\"subsection\"] = \".\".join(parts[:3])\n",
    "                if sec_title:\n",
    "                    # prefer explicit block title over TOC title\n",
    "                    meta[\"section_title\"] = sec_title\n",
    "\n",
    "            rec = {\n",
    "                \"type\": \"text\",\n",
    "                \"page_from\": page,\n",
    "                \"page_to\": page,\n",
    "                \"std\": std,\n",
    "                \"uri\": f\"/pdf/{pdf_name}\",\n",
    "                \"anchor\": f\"#page={page}\",\n",
    "                **meta,\n",
    "                \"content\": text,\n",
    "            }\n",
    "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "            total += 1\n",
    "\n",
    "    size_kb = out_path.stat().st_size / 1024.0\n",
    "    print(f\"[emit] wrote {total} records to {out_path} ({size_kb:.1f} KB)\")\n",
    "\n",
    "\n",
    "# === Write JSONL now ===\n",
    "write_jsonl(\n",
    "    out_path=OUT_JSONL_PATH,\n",
    "    pdf_name=PDF_PATH.name,\n",
    "    std=STD_TAG,\n",
    "    blocks_with_pages=blocks_with_pages,\n",
    "    toc_intervals=toc_intervals,\n",
    ")\n",
    "\n",
    "print(\"Done. JSONL ready at:\", OUT_JSONL_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
